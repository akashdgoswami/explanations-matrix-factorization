{
 "metadata": {
  "name": "check-grad"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Welcome to pylab, a matplotlib-based Python environment [backend: module://IPython.zmq.pylab.backend_inline].\n",
        "For more information, type 'help(pylab)'.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from copy import deepcopy\n",
      "import pickle\n",
      "\n",
      "import numpy as np\n",
      "from scipy.optimize import check_grad, approx_fprime\n",
      "import scipy.linalg\n",
      "\n",
      "import active_pmf\n",
      "import normal_exps as nexps\n",
      "import normal_exps_cy as nexps_cy\n",
      "import matrix_normal_exps_cy as mnexps_cy\n",
      "import mn_active_pmf\n",
      "import pmf_cy\n",
      "import pmf as pmf_pure"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pickle.load(open('../results/10x10_r4_d4_k4_K36/run1/data.pkl', 'rb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def stack_ll(u, v):\n",
      "    return np.hstack((u.reshape(-1), v.reshape(-1)))\n",
      "\n",
      "def unstack_ll(x, n, m, d):\n",
      "    return x[:n*d].reshape(n, d), x[n*d:].reshape(m, d)\n",
      "\n",
      "def ll(pmf):\n",
      "    n = pmf.num_users\n",
      "    m = pmf.num_items\n",
      "    d = pmf.latent_d\n",
      "    def inner(x):\n",
      "        return pmf.log_likelihood(*unstack_ll(x, n, m, d))\n",
      "    return inner\n",
      "\n",
      "def grad(pmf):\n",
      "    n = pmf.num_users\n",
      "    m = pmf.num_items\n",
      "    d = pmf.latent_d\n",
      "    a = deepcopy(pmf)\n",
      "    def inner(x):\n",
      "        a.users, a.items = unstack_ll(x, n, m, d)\n",
      "        return stack_ll(*a.gradient())\n",
      "    return inner"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for p in (pmf_pure, pmf_cy):\n",
      "    for sub_mean in (False, True):\n",
      "        pmf = p.ProbabilisticMatrixFactorization(data['_ratings'], 1, sub_mean)\n",
      "        x_ll = stack_ll(pmf.users, pmf.items)\n",
      "        print(check_grad(ll(pmf), grad(pmf), x_ll))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.90201301852e-06\n",
        "3.29453086977e-07\n",
        "1.88000559389e-06\n",
        "4.34644867091e-07\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def stack_kl(mean, cov):\n",
      "    return np.hstack((mean, cov[np.triu_indices_from(cov)]))\n",
      "\n",
      "def unstack_kl(x, k):\n",
      "    cov = np.zeros((k,k))\n",
      "    cov[np.triu_indices_from(cov)] = x[k:]\n",
      "    cov += cov.T # symmetrize\n",
      "    cov[np.diag_indices_from(cov)] /= 2 # correct diagonal\n",
      "    return x[:k], cov\n",
      "\n",
      "def kl(apmf):\n",
      "    k = apmf.approx_dim\n",
      "    def inner(x):\n",
      "        mean, cov = unstack_kl(x, k)\n",
      "        if np.any(cov != cov.T) or np.any(scipy.linalg.eigvalsh(cov) <= 0):\n",
      "            raise ValueError(\"covariance must be positive definite\")\n",
      "        return apmf.kl_divergence(mean, cov)\n",
      "    return inner\n",
      "\n",
      "def grad_kl(apmf, norm_grad=nexps.normal_gradient):\n",
      "    k = apmf.approx_dim\n",
      "    a = deepcopy(apmf)\n",
      "    def inner(x):\n",
      "        a.mean, a.cov = unstack_kl(x, k)\n",
      "        return stack_kl(*norm_grad(a))\n",
      "    return inner"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# (to reload after changes)\n",
      "from imp import reload\n",
      "reload(nexps); reload(nexps_cy); reload(mnexps_cy)\n",
      "reload(pmf_pure); reload(pmf_cy)\n",
      "reload(active_pmf); reload(mn_active_pmf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "<module 'mn_active_pmf' from './mn_active_pmf.py'>"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "apmf = active_pmf.ActivePMF(data['_ratings'], 2, data['_rating_vals'], True)\n",
      "apmf.initialize_approx()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_kl = stack_kl(apmf.mean, apmf.cov)\n",
      "check_grad(kl(apmf), grad_kl(apmf, nexps.normal_gradient), x_kl)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "544612.72465093376"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "approx = approx_fprime(x_kl, kl(apmf), np.sqrt(np.finfo(float).eps))\n",
      "calc = grad_kl(apmf, nexps_cy.normal_gradient)(x_kl)\n",
      "np.mean(np.abs((calc - approx) / calc))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "0.011605497601875188"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c_mn, c_cov = unstack_kl(calc, apmf.approx_dim)\n",
      "a_mn, a_cov = unstack_kl(approx, apmf.approx_dim)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.abs(c_mn - a_mn).max(), np.abs((c_cov - a_mn) / c_cov).max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 58,
       "text": [
        "(3.7417839215958537e-06, 1.2704374784369086)"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.unravel_index(np.abs((c_cov - a_cov) / c_cov).argmax(), c_cov.shape)\n",
      "# NOTE: there has to be a bug in this gradient, it always has exactly 1 element pretty far off\n",
      "# but it's always a different element...\n",
      "# we're not doing anything with it right now anyway, so just ignore it. :("
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "(20, 27)"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i = np.argmax(np.abs((calc - approx) / calc))\n",
      "i, calc[i], approx[i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "(657, -8.1550564093142786, 3.1811294555664062)"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hist((calc - approx) / calc, log=True, bins=50)\n",
      "None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEBCAYAAACUmXXrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhxD6AOAQQh8AHELoA4BD/h9DVFAWWfvKHwAAAABJRU5ErkJggg==\n"
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def stack_mn_kl(mean, cov_useritems, cov_latents):\n",
      "    return np.hstack((mean.ravel(),\n",
      "                      cov_useritems[np.triu_indices_from(cov_useritems)],\n",
      "                      cov_latents[np.triu_indices_from(cov_latents)]))\n",
      "\n",
      "def _unstack_cov(vals, dim):\n",
      "    cov = np.zeros((dim, dim))\n",
      "    cov[np.triu_indices_from(cov)] = vals\n",
      "    cov += cov.T\n",
      "    cov[np.diag_indices_from(cov)] /= 2\n",
      "    return cov\n",
      "\n",
      "def unstack_mn_kl(x, n_useritems, latent_d):\n",
      "    num_mean = n_useritems * latent_d\n",
      "    num_useritems = n_useritems * (n_useritems + 1) // 2\n",
      "    num_latents = latent_d * (latent_d + 1) // 2\n",
      "    assert num_mean + num_useritems + num_latents == x.size, \\\n",
      "           (num_mean, num_useritems, num_latents, x.size)\n",
      "    \n",
      "    mean = x[:num_mean].reshape((n_useritems, latent_d))\n",
      "    cov_useritems = _unstack_cov(x[num_mean:-num_latents], n_useritems)\n",
      "    cov_latents = _unstack_cov(x[-num_latents:], latent_d)\n",
      "    return mean, cov_useritems, cov_latents\n",
      "\n",
      "def _check_cov(cov):\n",
      "    if np.any(cov != cov.T) or np.any(scipy.linalg.eigvalsh(cov) <= 0):\n",
      "       raise ValueError(\"covariance must be positive definite\")\n",
      "    \n",
      "def mn_kl(mn_apmf):\n",
      "    n_useritems = mn_apmf.num_users + mn_apmf.num_items\n",
      "    latent_d = mn_apmf.latent_d\n",
      "    def inner(x):\n",
      "        mean, cov_useritems, cov_latents = unstack_mn_kl(x, n_useritems, latent_d)\n",
      "        _check_cov(cov_useritems)\n",
      "        _check_cov(cov_latents)\n",
      "        return mn_apmf.kl_divergence(mean, cov_useritems, cov_latents)\n",
      "    return inner\n",
      "\n",
      "def grad_mn_kl(mn_apmf, norm_grad=mnexps_cy.matrixnormal_gradient):\n",
      "    n_useritems = mn_apmf.num_users + mn_apmf.num_items\n",
      "    a = deepcopy(mn_apmf)\n",
      "    def inner(x):\n",
      "        a.mean, a.cov_useritems, a.cov_latents = unstack_mn_kl(x, n_useritems, a.latent_d)\n",
      "        return stack_mn_kl(*norm_grad(a))\n",
      "    return inner"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mnapmf = mn_active_pmf.MNActivePMF(data['_ratings'], 2, data['_rating_vals'], True)\n",
      "mnapmf.initialize_approx(random_cov=True)\n",
      "np.linalg.eigvalsh(mnapmf.cov_useritems), np.linalg.eigvalsh(mnapmf.cov_latents)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "(array([  2.86165711e-02,   2.58024536e-01,   8.46325976e-01,\n",
        "         1.18720349e+00,   1.93688690e+00,   2.47915613e+00,\n",
        "         4.63441990e+00,   7.97666656e+00,   8.78688373e+00,\n",
        "         1.02632909e+01,   1.27434221e+01,   1.60171246e+01,\n",
        "         2.38723209e+01,   2.83998679e+01,   3.60016854e+01,\n",
        "         4.18239086e+01,   4.71392493e+01,   4.97768746e+01,\n",
        "         5.74934570e+01,   8.37923782e+01]),\n",
        " array([ 0.14667314,  2.57315165]))"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def quadexp(n_users, n_items, latent_d, i, j, k, l, mult=1):\n",
      "    n_useritems = n_users + n_items\n",
      "    j_ = n_users + j\n",
      "    def inner(x):\n",
      "        mean, cov_useritems, cov_latents = unstack_mn_kl(x, n_useritems, latent_d)\n",
      "        #cov_useritems = active_pmf.project_psd(cov_useritems, min_eig=1e-3)\n",
      "        #cov_latents = active_pmf.project_psd(cov_latents, min_eig=1e-3)\n",
      "        _check_cov(cov_useritems)\n",
      "        _check_cov(cov_latents)\n",
      "        return mnexps_cy.quadexpect(mean, cov_useritems, cov_latents,\n",
      "                                    i, k,  j_, k,  i, l,  j_, l) * mult\n",
      "    return inner\n",
      "\n",
      "def grad_quadexp(n_users, n_items, latent_d, i, j, k, l, mult=1):\n",
      "    n_useritems = n_users + n_items\n",
      "    def inner(x):\n",
      "        mean, cov_useritems, cov_latents = unstack_mn_kl(x, n_useritems, latent_d)\n",
      "        _check_cov(cov_useritems)\n",
      "        _check_cov(cov_latents)\n",
      "        g_mean = np.zeros_like(mean)\n",
      "        g_cov_useritems = np.zeros_like(cov_useritems)\n",
      "        g_cov_latents = np.zeros_like(cov_latents)\n",
      "        mnexps_cy._quadexp_grad(n_users, mean, cov_useritems, cov_latents,\n",
      "                                g_mean, g_cov_useritems, g_cov_latents,\n",
      "                                i, j, k, l, mult)\n",
      "        return stack_mn_kl(g_mean, g_cov_useritems, g_cov_latents)\n",
      "    return inner\n",
      "\n",
      "\n",
      "i = 4\n",
      "j = 1\n",
      "k = 0\n",
      "l = 1\n",
      "\n",
      "quad = quadexp(mnapmf.num_users, mnapmf.num_items, mnapmf.latent_d, i, j, k, l)\n",
      "g_quad = grad_quadexp(mnapmf.num_users, mnapmf.num_items, mnapmf.latent_d, i, j, k, l)\n",
      "\n",
      "x_mn_kl = stack_mn_kl(mnapmf.mean, mnapmf.cov_useritems, mnapmf.cov_latents)\n",
      "\n",
      "approx = approx_fprime(x_mn_kl, quad, np.sqrt(np.finfo(float).eps))\n",
      "calc = g_quad(x_mn_kl)\n",
      "\n",
      "idx = (calc != 0) | (approx != 0)\n",
      "np.vstack((# np.arange(approx.size)[idx], \n",
      "           approx[idx], calc[idx])).T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "array([[ -7.30491288e-01,  -7.30491296e-01],\n",
        "       [  4.15037178e-01,   4.15037177e-01],\n",
        "       [ -6.43390225e-01,  -6.43390223e-01],\n",
        "       [  3.75165543e-01,   3.75165537e-01],\n",
        "       [  2.75773592e-02,   2.75773565e-02],\n",
        "       [  4.16405657e-01,   4.16405656e-01],\n",
        "       [  2.48451680e-02,   2.48451702e-02],\n",
        "       [  2.58383406e+00,   2.58383406e+00],\n",
        "       [  3.03274678e+01,   3.03274627e+01],\n",
        "       [ -3.21550516e-01,  -3.21550520e-01]])"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sqexp(n_users, n_items, latent_d, i, j, k, mult=1):\n",
      "    n_useritems = n_users + n_items\n",
      "    j_ = n_users + j\n",
      "    def inner(x):\n",
      "        mean, cov_useritems, cov_latents = unstack_mn_kl(x, n_useritems, latent_d)\n",
      "        #cov_useritems = active_pmf.project_psd(cov_useritems, min_eig=1e-3)\n",
      "        #cov_latents = active_pmf.project_psd(cov_latents, min_eig=1e-3)\n",
      "        _check_cov(cov_useritems)\n",
      "        _check_cov(cov_latents)\n",
      "        return mnexps_cy.exp_squared(mean, cov_useritems, cov_latents,\n",
      "                                    i, k,  j_, k) * mult\n",
      "    return inner\n",
      "\n",
      "def grad_sqexp(n_users, n_items, latent_d, i, j, k, mult=1):\n",
      "    n_useritems = n_users + n_items\n",
      "    def inner(x):\n",
      "        mean, cov_useritems, cov_latents = unstack_mn_kl(x, n_useritems, latent_d)\n",
      "        _check_cov(cov_useritems)\n",
      "        _check_cov(cov_latents)\n",
      "        g_mean = np.zeros_like(mean)\n",
      "        g_cov_useritems = np.zeros_like(cov_useritems)\n",
      "        g_cov_latents = np.zeros_like(cov_latents)\n",
      "        mnexps_cy._squareexp_grad(n_users, mean, cov_useritems, cov_latents,\n",
      "                                g_mean, g_cov_useritems, g_cov_latents,\n",
      "                                i, j, k, mult)\n",
      "        return stack_mn_kl(g_mean, g_cov_useritems, g_cov_latents)\n",
      "    return inner\n",
      "\n",
      "\n",
      "i = 4\n",
      "j = 1\n",
      "k = 0\n",
      "\n",
      "f = sqexp(mnapmf.num_users, mnapmf.num_items, mnapmf.latent_d, i, j, k, l)\n",
      "g = grad_sqexp(mnapmf.num_users, mnapmf.num_items, mnapmf.latent_d, i, j, k, l)\n",
      "\n",
      "x_mn_kl = stack_mn_kl(mnapmf.mean, mnapmf.cov_useritems, mnapmf.cov_latents)\n",
      "\n",
      "approx = approx_fprime(x_mn_kl, f, np.sqrt(np.finfo(float).eps))\n",
      "calc = g(x_mn_kl)\n",
      "\n",
      "idx = ((calc != 0) | (approx != 0)) & (np.isfinite(approx) | (calc != 0))\n",
      "np.vstack((# np.arange(approx.size)[idx], \n",
      "           approx[idx], calc[idx])).T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "array([[  3.05819198e-01,   3.05819192e-01],\n",
        "       [  3.02944732e-01,   3.02944728e-01],\n",
        "       [  1.17089413e-03,   1.17089465e-03],\n",
        "       [  3.57614830e-03,   3.57614861e-03],\n",
        "       [  1.15198269e-03,   1.15198183e-03],\n",
        "       [  1.03289435e+01,   1.03289384e+01]])"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_mn_kl = stack_mn_kl(mnapmf.mean, mnapmf.cov_useritems, mnapmf.cov_latents)\n",
      "approx = approx_fprime(x_mn_kl, mn_kl(mnapmf), np.sqrt(np.finfo(float).eps))\n",
      "calc = grad_mn_kl(mnapmf, mnexps_cy.matrixnormal_gradient)(x_mn_kl)\n",
      "np.mean((np.abs((calc - approx) / calc))[calc != 0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "0.00022125288265041368"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.max(np.abs((calc - approx) / calc))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "0.0065100444885730939"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_useritems = mnapmf.num_users + mnapmf.num_items\n",
      "np.transpose(np.triu_indices(mnapmf.latent_d)) \\\n",
      "    [250 - n_useritems * mnapmf.latent_d - n_useritems * (n_useritems + 1) // 2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "array([0, 0])"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hist((calc - approx)[calc != 0] / calc[calc != 0], log=True, bins=50)\n",
      "None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEBCAYAAACaHMnBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAQBAhAEAQIQBAECEAQBAhAEAQNL/AdGnz9Lu2zDCAAAAAElFTkSuQmCC\n"
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c_mean, c_cov_useritems, c_cov_latents = unstack_mn_kl(calc, mnapmf.num_users+mnapmf.num_items, mnapmf.latent_d)\n",
      "a_mean, a_cov_useritems, a_cov_latents = unstack_mn_kl(approx, mnapmf.num_users+mnapmf.num_items, mnapmf.latent_d)\n",
      "np.dstack((a_cov_latents, c_cov_latents))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "array([[[  29248.43359375,  115653.41222713],\n",
        "        [ -22837.59375   ,  -22837.59416095]],\n",
        "\n",
        "       [[ -22837.59375   ,  -22837.59416095],\n",
        "        [   9126.04296875,   31558.51833908]]])"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "20*1 + 20 * 21 // 2 + 1 * 2 // 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "231"
       ]
      }
     ],
     "prompt_number": 29
    }
   ],
   "metadata": {}
  }
 ]
}